{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study of SSPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "os.chdir('../..')\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebooks.ssps.utils import (\n",
    "    evaluate_sv,\n",
    "    plot_inter_speaker_center_similarity,\n",
    "    plot_inter_class_similarity,\n",
    "    plot_intra_class_similarity,\n",
    "    plot_intra_class_similarity_by_class\n",
    ")\n",
    "\n",
    "from notebooks.evaluation.sv_visualization import (\n",
    "    det_curve,\n",
    "    scores_distribution,\n",
    "    tsne_2D,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on SV (Vox1-O/E/H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = evaluate_sv([\n",
    "    \"models/ssps/voxceleb2/simclr/baseline/config.yml\",\n",
    "    \"models/ssps/voxceleb2/simclr/2-kmeans_exp-10-0.5/config.yml\",\n",
    "    \"models/ssps/voxceleb2/simclr/baseline_sup/config.yml\",\n",
    "    \"models/ssps/voxceleb2/simclr/baseline_sup_aam/config.yml\",\n",
    "], 'embeddings_vox1_epoch-100.pt', trials=[\n",
    "    \"voxceleb1_test_O\",\n",
    "    \"voxceleb1_test_E\",\n",
    "    \"voxceleb1_test_H\",\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inter-speaker similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VoxCeleb1-O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inter_class_similarity('speaker', {\n",
    "    'SSL': 'models/ssps/voxceleb2/simclr/baseline/embeddings_vox1o_epoch-100.pt',\n",
    "    'SSPS': 'models/ssps/voxceleb2/simclr/2-kmeans_exp-10-0.5/embeddings_vox1o_epoch-100.pt',\n",
    "    # 'SSL (supervised)': 'models/ssps/voxceleb2/simclr/baseline_sup/embeddings_vox1o_epoch-100.pt',\n",
    "    'AAM-Softmax': 'models/ssps/voxceleb2/simclr/baseline_sup_aam/embeddings_vox1o_epoch-100.pt',\n",
    "}, nb_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inter_speaker_center_similarity({\n",
    "    'SSL': 'models/ssps/voxceleb2/simclr/baseline/embeddings_vox1o_epoch-100.pt',\n",
    "    'SSPS': 'models/ssps/voxceleb2/simclr/2-kmeans_exp-10-0.5/embeddings_vox1o_epoch-100.pt',\n",
    "    # 'SSL (supervised)': 'models/ssps/voxceleb2/simclr/baseline_sup/embeddings_vox1_epoch-100.pt',\n",
    "    'AAM-Softmax': 'models/ssps/voxceleb2/simclr/baseline_sup_aam/embeddings_vox1o_epoch-100.pt',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VoxCeleb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inter_class_similarity('speaker', {\n",
    "    'SSL': 'models/ssps/voxceleb2/simclr/baseline/embeddings_vox1_epoch-100.pt',\n",
    "    'SSPS': 'models/ssps/voxceleb2/simclr/2-kmeans_exp-10-0.5/embeddings_vox1_epoch-100.pt',\n",
    "    # 'SSL (supervised)': 'models/ssps/voxceleb2/simclr/baseline_sup/embeddings_vox1_epoch-100.pt',\n",
    "    'AAM-Softmax': 'models/ssps/voxceleb2/simclr/baseline_sup_aam/embeddings_vox1_epoch-100.pt',\n",
    "}, nb_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inter_speaker_center_similarity({\n",
    "    'SSL': 'models/ssps/voxceleb2/simclr/baseline/embeddings_vox1_epoch-100.pt',\n",
    "    'SSPS': 'models/ssps/voxceleb2/simclr/2-kmeans_exp-10-0.5/embeddings_vox1_epoch-100.pt',\n",
    "    # 'SSL (supervised)': 'models/ssps/voxceleb2/simclr/baseline_sup/embeddings_vox1_epoch-100.pt',\n",
    "    'AAM-Softmax': 'models/ssps/voxceleb2/simclr/baseline_sup_aam/embeddings_vox1_epoch-100.pt',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VoxCeleb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inter_class_similarity('speaker', {\n",
    "    'SSL': 'models/ssps/voxceleb2/simclr/baseline/embeddings_vox2_epoch-100.pt',\n",
    "    'SSPS': 'models/ssps/voxceleb2/simclr/2-kmeans_exp-10-0.5/embeddings_vox2_epoch-100.pt',\n",
    "    # 'SSL (supervised)': 'models/ssps/voxceleb2/simclr/baseline_sup/embeddings_vox2_epoch-100.pt',\n",
    "    # 'AAM-Softmax': 'models/ssps/voxceleb2/simclr/baseline_sup_aam/embeddings_vox2_epoch-100.pt',\n",
    "}, nb_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inter_speaker_center_similarity({\n",
    "    'SSL': 'models/ssps/voxceleb2/simclr/baseline/embeddings_vox2_epoch-100.pt',\n",
    "    'SSPS': 'models/ssps/voxceleb2/simclr/2-kmeans_exp-10-0.5/embeddings_vox2_epoch-100.pt',\n",
    "    # 'SSL (supervised)': 'models/ssps/voxceleb2/simclr/baseline_sup/embeddings_vox1_epoch-100.pt',\n",
    "    # 'AAM-Softmax': 'models/ssps/voxceleb2/simclr/baseline_sup_aam/embeddings_vox1_epoch-100.pt',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intra-speaker similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_intra_class_similarity('speaker', {\n",
    "    'SSL': 'models/ssps/voxceleb2/simclr/baseline/embeddings_vox1_epoch-100.pt',\n",
    "    'SSPS': 'models/ssps/voxceleb2/simclr/2-kmeans_exp-10-0.5/embeddings_vox1_epoch-100.pt',\n",
    "    'SSL (supervised)': 'models/ssps/voxceleb2/simclr/baseline_sup/embeddings_vox1_epoch-100.pt',\n",
    "    'AAM-Softmax': 'models/ssps/voxceleb2/simclr/baseline_sup_aam/embeddings_vox1_epoch-100.pt',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_intra_class_similarity_by_class('speaker', {\n",
    "    'SSL': 'models/ssps/voxceleb2/simclr/baseline/embeddings_vox1_epoch-100.pt',\n",
    "    'SSPS': 'models/ssps/voxceleb2/simclr/2-kmeans_exp-10-0.5/embeddings_vox1_epoch-100.pt',\n",
    "}, nb_classes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inter-video similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inter_class_similarity('video', {\n",
    "    'SSL': 'models/ssps/voxceleb2/simclr/baseline/embeddings_vox1_epoch-100.pt',\n",
    "    'SSPS': 'models/ssps/voxceleb2/simclr/2-kmeans_exp-10-0.5/embeddings_vox1_epoch-100.pt',\n",
    "    # 'SSL (supervised)': 'models/ssps/voxceleb2/simclr/baseline_sup/embeddings_vox1_epoch-100.pt',\n",
    "    'AAM-Softmax': 'models/ssps/voxceleb2/simclr/baseline_sup_aam/embeddings_vox1_epoch-100.pt',\n",
    "}, nb_samples=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intra-video similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_intra_class_similarity('video', {\n",
    "    'SSL': 'models/ssps/voxceleb2/simclr/baseline/embeddings_vox1_epoch-100.pt',\n",
    "    'SSPS': 'models/ssps/voxceleb2/simclr/2-kmeans_exp-10-0.5/embeddings_vox1_epoch-100.pt',\n",
    "    'SSL (supervised)': 'models/ssps/voxceleb2/simclr/baseline_sup/embeddings_vox1_epoch-100.pt',\n",
    "    'AAM-Softmax': 'models/ssps/voxceleb2/simclr/baseline_sup_aam/embeddings_vox1_epoch-100.pt',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Dict\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Model:\n",
    "\n",
    "    scores: List[float] = None\n",
    "    targets: List[int] = None\n",
    "    embeddings: Dict[str, torch.Tensor] = None\n",
    "\n",
    "\n",
    "def get_models_for_visualization(scores, names=None):\n",
    "    if names is None:\n",
    "        names = list(scores.keys())\n",
    "\n",
    "    models = {\n",
    "        k:Model(v['scores'], v['targets'])\n",
    "        for k, v\n",
    "        in scores.items()\n",
    "        if k in names\n",
    "    }\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_distribution(get_models_for_visualization(scores, [\n",
    "    \"baseline\",\n",
    "    \"2-kmeans_exp-10-0.5\",\n",
    "]), use_angle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_distribution(get_models_for_visualization(scores, [\n",
    "    \"baseline_sup\",\n",
    "    \"baseline_sup_aam\",\n",
    "]), use_angle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DET curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_curve(get_models_for_visualization(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_init = tsne_2D(Model(\n",
    "    embeddings=torch.load(\"models/ssps/voxceleb2/simclr/baseline/embeddings_vox1_epoch-100.pt\")\n",
    "))\n",
    "\n",
    "_ = tsne_2D(Model(\n",
    "    embeddings=torch.load(\"models/ssps/voxceleb2/simclr/2-kmeans_exp-10-0.5/embeddings_vox1_epoch-100.pt\")\n",
    "), init=tsne_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Vox1 metadata from representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def fit_mlp_on_representations(embeddings, y_key_pos, test_size=0.2):\n",
    "    keys = list(embeddings.keys())\n",
    "    \n",
    "    X = [embeddings[key][0].numpy() for key in keys]\n",
    "    if y_key_pos is None:\n",
    "        y = keys\n",
    "    else:\n",
    "        y = [key.split('/')[y_key_pos] for key in keys]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=0\n",
    "    )\n",
    "    \n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    print(f'Train accuracy: {clf.score(X_train, y_train)}')\n",
    "    print(f'Test accuracy: {clf.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_embeddings = torch.load(\"models/ssps/voxceleb2/simclr/baseline/embeddings_vox1o_epoch-100.pt\")\n",
    "ssps_embeddings = torch.load(\"models/ssps/voxceleb2/simclr/2-kmeans_exp-10-0.5/embeddings_vox1o_epoch-100.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = fit_mlp_on_representations(baseline_embeddings, y_key_pos=-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = fit_mlp_on_representations(ssps_embeddings, y_key_pos=-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = fit_mlp_on_representations(baseline_embeddings, y_key_pos=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = fit_mlp_on_representations(ssps_embeddings, y_key_pos=-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = fit_mlp_on_representations(baseline_embeddings, y_key_pos=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = fit_mlp_on_representations(ssps_embeddings, y_key_pos=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means assignments distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from plotnine import ggplot, aes, geom_bar, labs, theme_bw, theme, element_text, coord_cartesian\n",
    "\n",
    "\n",
    "def plot_kmeans_cluster_distribution(checkpoint):\n",
    "    assignments = torch.load(checkpoint).cpu()\n",
    "\n",
    "    cluster_counts = torch.bincount(assignments[assignments > 1])\n",
    "\n",
    "    data = pd.DataFrame({'elements_in_cluster': cluster_counts.numpy()})\n",
    "    cluster_histogram = data['elements_in_cluster'].value_counts().reset_index()\n",
    "    cluster_histogram.columns = ['x_elements', 'count']\n",
    "\n",
    "    p = (\n",
    "        ggplot(cluster_histogram, aes(x='x_elements', y='count'))\n",
    "        + geom_bar(stat='identity')\n",
    "        + labs(\n",
    "            x='Number of samples',\n",
    "            y='Count',\n",
    "            title='K-means cluster distribution'\n",
    "        )\n",
    "        + theme_bw()\n",
    "        + theme(figure_size=(12, 8), text=element_text(size=14))\n",
    "    )\n",
    "    print(p)\n",
    "\n",
    "    cluster_histogram['type'] = 'K-means'\n",
    "\n",
    "    stats = {\n",
    "        'min': data['elements_in_cluster'].min(),\n",
    "        'max': data['elements_in_cluster'].max(),\n",
    "        'median': data['elements_in_cluster'].median(),\n",
    "        'mean': data['elements_in_cluster'].mean(),\n",
    "        'zero_count': (data['elements_in_cluster'] == 0).sum()\n",
    "    }\n",
    "\n",
    "    return stats, cluster_histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats, kmeans_50k_hist = plot_kmeans_cluster_distribution(\"models/ssps/voxceleb2/simclr/2-kmeans_exp-10-0.5/assignments_epoch-100.pt\")\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats, kmeans_150k_hist = plot_kmeans_cluster_distribution(\"models/ssps/voxceleb2/simclr/2-kmeans-repr_150k/assignments_epoch-100.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def plot_vox_video_distribution(path):\n",
    "    res = defaultdict(int)\n",
    "\n",
    "    for file in glob(path):\n",
    "        video = file.split('/')[-2]\n",
    "        res[video] += 1\n",
    "\n",
    "    data2 = pd.DataFrame({'elements_in_video': list(res.values())})\n",
    "    cluster_histogram = data2['elements_in_video'].value_counts().reset_index()\n",
    "    cluster_histogram.columns = ['x_elements', 'count']\n",
    "\n",
    "    p = (\n",
    "        ggplot(cluster_histogram, aes(x='x_elements', y='count'))\n",
    "        + geom_bar(stat='identity')\n",
    "        + labs(\n",
    "            x='Number of samples',\n",
    "            y='Count',\n",
    "            title='VoxCeleb2 video distribution'\n",
    "        )\n",
    "        + theme_bw()\n",
    "        + theme(figure_size=(12, 8), text=element_text(size=14))\n",
    "    )\n",
    "    print(p)\n",
    "\n",
    "    cluster_histogram['type'] = 'VoxCeleb2'\n",
    "\n",
    "    stats = {\n",
    "        'min': data2['elements_in_video'].min(),\n",
    "        'max': data2['elements_in_video'].max(),\n",
    "        'median': data2['elements_in_video'].median(),\n",
    "        'mean': data2['elements_in_video'].mean()\n",
    "    }\n",
    "\n",
    "    return stats, cluster_histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats, vox2_hist = plot_vox_video_distribution('data/voxceleb2/*/*/*.wav')\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.concat([kmeans_150k_hist, vox2_hist], ignore_index=True)\n",
    "\n",
    "p = (\n",
    "    ggplot(combined_data, aes(x='x_elements', y='count', fill='type'))\n",
    "    + geom_bar(stat='identity', position='identity', alpha=0.7)\n",
    "    + labs(\n",
    "        x='Number of samples per cluster/video',\n",
    "        y='Count',\n",
    "        title='VoxCeleb2 videos and K-means clusters distribution'\n",
    "    )\n",
    "    + coord_cartesian(xlim=(0, 50))\n",
    "    + theme_bw()\n",
    "    + theme(figure_size=(12, 8), text=element_text(size=14))\n",
    ")\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency on data-aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  train SSL without aug\n",
    "# \"val/sv_cosine/voxceleb1_test_O/eer\": 15.551537070524413,\n",
    "# \"val/sv_cosine/voxceleb1_test_O/mindcf\": 0.7550674893955924\n",
    "\n",
    "#  train SSPS without aug\n",
    "# val/sv_cosine/voxceleb1_test_O/eer: 10.388644\n",
    "# val/sv_cosine/voxceleb1_test_O/mindcf: 0.691761"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholds: SSPS metrics vs SV metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from glob import glob\n",
    "import re\n",
    "\n",
    "from plotnine import ggplot, aes, geom_line, geom_vline, geom_point, theme, theme_bw, labs, scale_x_continuous, element_text\n",
    "import patchworklib as pw\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "exps = glob(\"models/ssps/voxceleb2/simclr/2-kmeans-repr_tau1-*_tau2-*\")\n",
    "\n",
    "res = []\n",
    "for exp in exps:\n",
    "    try:\n",
    "        with open(exp + \"/training.json\", \"r\") as f:\n",
    "            data = json.load(f)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    tau1 = float(re.search(r'tau1-([\\d.]+)_tau2-([\\d.]+)', exp.split('/')[-1]).group(1))\n",
    "    tau2 = float(re.search(r'tau1-([\\d.]+)_tau2-([\\d.]+)', exp.split('/')[-1]).group(2))\n",
    "\n",
    "    if tau2 in [0.95, 0.975]:\n",
    "        continue\n",
    "\n",
    "    cost = data[\"100\"][\"ssps_speaker_acc\"] + (1 - data[\"100\"][\"ssps_video_acc\"]) + data[\"100\"][\"ssps_coverage\"]\n",
    "    cost = 3 - cost\n",
    "\n",
    "    res.append({\n",
    "        'tau1': tau1,\n",
    "        'tau2': tau2,\n",
    "        'ssps_cost': cost,\n",
    "        **data[\"100\"]\n",
    "    })\n",
    "\n",
    "data = pd.DataFrame(res)\n",
    "\n",
    "def create_plot(y, label):\n",
    "    p = (\n",
    "        ggplot(data, aes(x='tau1', y=y, color='factor(tau2)'))\n",
    "        + geom_line()\n",
    "        + geom_point()\n",
    "        + geom_vline(xintercept=0.835, linetype='dashed', color='black')\n",
    "        + labs(title=label, x='τ₁', y=None, color='τ₂')\n",
    "        + scale_x_continuous(breaks=data['tau1'])\n",
    "        # + theme_bw()\n",
    "        + theme(\n",
    "            figure_size=(6, 5),\n",
    "            text=element_text(size=14),\n",
    "            plot_title=element_text(\n",
    "                ha=\"left\",\n",
    "                # x=0.535,\n",
    "                margin={'b': 0 if y == 'ssps_speaker_acc' else 90}\n",
    "            ),\n",
    "            axis_text_x=element_text(angle=45, ha=\"right\")\n",
    "        )\n",
    "    )\n",
    "    p = pw.load_ggplot(p)\n",
    "    return p\n",
    "\n",
    "\n",
    "g_spkacc = create_plot('ssps_speaker_acc', 'Speaker Accuracy (%)')\n",
    "g_vidacc = create_plot('ssps_video_acc', 'Video Accuracy (%)')\n",
    "g_coverage = create_plot('ssps_coverage', 'Coverage (%)')\n",
    "g_cost = create_plot('ssps_cost', 'SSPS cost')\n",
    "g_interpool = create_plot('ssps_inter_sampling_pool', 'Inter-sampling pool size')\n",
    "g_intrapool = create_plot('ssps_intra_sampling_pool', 'Intra-sampling pool size')\n",
    "g_eer = create_plot('val/sv_cosine/voxceleb1_test_O/eer', 'EER (%)')\n",
    "g_mindcf = create_plot('val/sv_cosine/voxceleb1_test_O/mindcf', 'minDCF (p=0.01)')\n",
    "\n",
    "# p = (g_eer|g_mindcf)/(g_spkacc|g_vidacc|g_coverage)\n",
    "# p = (g_eer|g_spkacc|g_vidacc)/(g_coverage|g_interpool|g_intrapool)\n",
    "# p = (g_eer|g_mindcf)/(g_spkacc|g_vidacc)/(g_coverage|g_interpool|g_intrapool)\n",
    "p = (g_eer|g_mindcf|g_cost)/(g_spkacc|g_vidacc|g_coverage)\n",
    "\n",
    "p.set_suptitle(\n",
    "    \"SV and SSPS metrics with different thresholds\",\n",
    "    fontsize=20,\n",
    "    pad=40\n",
    ")\n",
    "p.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "cmds = []\n",
    "\n",
    "for lamba in tqdm((1.2, 0.8, 0.5, 0.2, 0.0, -0.2, -0.5, -0.8, -1.2)):\n",
    "    exp = f'models/ssps/voxceleb2/simclr/default_inter-10-{lamba}'\n",
    "\n",
    "    # Create experiment folder\n",
    "    Path(exp).mkdir(exist_ok=True)\n",
    "\n",
    "    # Create config file\n",
    "    with open('models/ssps/voxceleb2/simclr/default/config.yml') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    data['method']['ssps']['inter_sampling_prob_exp_lambda'] = lamba\n",
    "    data['trainer']['epochs'] = 101\n",
    "    with open(exp + '/config.yml', 'w') as f:\n",
    "        yaml.dump(data, f)\n",
    "\n",
    "    # Copy latest checkpoint\n",
    "    (Path(exp) / \"checkpoints\").mkdir(exist_ok=True)\n",
    "    # shutil.copy(\n",
    "    #     \"models/ssps/voxceleb2/simclr/model_base.pt\",\n",
    "    #     (Path(exp) / \"checkpoints\" / \"model_latest.pt\")\n",
    "    # )\n",
    "\n",
    "    cmds.append(f\"\\\"{exp.split('/')[-1]}\\\"\")\n",
    "\n",
    "' '.join(cmds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
