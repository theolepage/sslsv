{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study of SSPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "os.chdir('../..')\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebooks.ssps.utils import (\n",
    "    evaluate_sv,\n",
    "    plot_inter_speaker_center_similarity,\n",
    "    plot_inter_class_similarity,\n",
    "    plot_intra_class_similarity,\n",
    "    plot_intra_class_similarity_by_class\n",
    ")\n",
    "\n",
    "from notebooks.evaluation.sv_visualization import (\n",
    "    det_curve,\n",
    "    scores_distribution,\n",
    "    tsne_2D,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Dict\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Model:\n",
    "\n",
    "    scores: List[float] = None\n",
    "    targets: List[int] = None\n",
    "    embeddings: Dict[str, torch.Tensor] = None\n",
    "\n",
    "\n",
    "def get_models_for_visualization(scores, names=None):\n",
    "    if names is None:\n",
    "        names = list(scores.keys())\n",
    "\n",
    "    models = {\n",
    "        k:Model(v['scores'], v['targets'])\n",
    "        for k, v\n",
    "        in scores.items()\n",
    "        if k in names\n",
    "    }\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling hyper-params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotnine import (\n",
    "    ggplot,\n",
    "    aes,\n",
    "    geom_line,\n",
    "    geom_point,\n",
    "    labs,\n",
    "    theme_bw,\n",
    "    scale_x_continuous,\n",
    "    scale_y_continuous,\n",
    "    scale_color_discrete,\n",
    "    geom_text,\n",
    "    theme,\n",
    "    element_text,\n",
    "    element_blank,\n",
    "    element_rect,\n",
    "    guides,\n",
    "    guide_legend\n",
    ")\n",
    "\n",
    "\n",
    "# Parameters\n",
    "N = 10\n",
    "decays = [0.2, 0.5, 1.0, 2.0]\n",
    "# decays = [0.1, 0.4, 0.6, 0.8, 1.0, 1.2, 1.7, 2.5, 4.0]\n",
    "\n",
    "# Generate data for each decay\n",
    "data = []\n",
    "for decay in decays:\n",
    "    if decay == 0.0:\n",
    "        method = 'uniform'\n",
    "        probs = torch.ones(N) / N\n",
    "    else:\n",
    "        method = f'Î»={decay}'\n",
    "        probs = decay * torch.exp(-decay * torch.arange(N).float())\n",
    "    probs = (probs / probs.sum()).numpy()\n",
    "\n",
    "    # Add the data to the list\n",
    "    for idx, prob in enumerate(probs):\n",
    "        data.append({'Index': idx, 'Probability': prob, 'Method': method})\n",
    "\n",
    "# Create the plot\n",
    "df = pd.DataFrame(data)\n",
    "p = (\n",
    "    ggplot(df, aes(x='Index', y='Probability', color='Method'))\n",
    "    + geom_line(aes(group='Method'), size=0.75)\n",
    "    + geom_point(size=1)\n",
    "    + labs(title=f'Sampling probability distribution (N={N})')\n",
    "    + scale_x_continuous(breaks=range(N))\n",
    "    + scale_y_continuous(breaks=np.arange(0, 1.1, 0.1))\n",
    "    + scale_color_discrete(\n",
    "        limits=df.Method.unique()\n",
    "    )\n",
    "    + guides(color=guide_legend(nrow=1, byrow=True))\n",
    "    + theme_bw()\n",
    "    + theme(\n",
    "        figure_size=(12, 7),\n",
    "        text=element_text(size=10),\n",
    "        axis_title_x=element_blank(),\n",
    "        axis_title_y=element_blank(),\n",
    "        legend_title=element_blank(),\n",
    "        legend_position=(0.5, 0.83),\n",
    "        legend_direction='horizontal',\n",
    "    )\n",
    ")\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSPS-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from glob import glob\n",
    "import re\n",
    "\n",
    "from plotnine import ggplot, aes, geom_line, geom_vline, geom_point, theme, theme_bw, labs, scale_x_continuous, scale_color_discrete, element_text\n",
    "import patchworklib as pw\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "exps = [\n",
    "    \"models/ssps/voxceleb2/simclr/ssps_knn_uni-1\",\n",
    "    \"models/ssps/voxceleb2/simclr/ssps_knn_uni-10\",\n",
    "    \"models/ssps/voxceleb2/simclr/ssps_knn_uni-50\",\n",
    "    \"models/ssps/voxceleb2/simclr/ssps_knn_uni-100\",\n",
    "    \"models/ssps/voxceleb2/simclr/ssps_knn_uni-200\",\n",
    "]\n",
    "\n",
    "\n",
    "res = []\n",
    "for exp in exps:\n",
    "    with open(exp + \"/training.json\", \"r\") as f:\n",
    "        train = json.load(f)\n",
    "\n",
    "    with open(exp + \"/evaluation.json\", \"r\") as f:\n",
    "        eval = json.load(f)\n",
    "\n",
    "    sampling = re.search(r'uni-([\\w\\d.]+)', exp.split('/')[-1])\n",
    "    if sampling:\n",
    "        sampling = int(sampling.group(1))\n",
    "    else:\n",
    "        sampling = 0\n",
    "\n",
    "    res.append({\n",
    "        'sampling': sampling,\n",
    "        **train[\"109\"],\n",
    "        **eval\n",
    "    })\n",
    "\n",
    "data = pd.DataFrame(res)\n",
    "\n",
    "def create_plot(y, label):\n",
    "    p = (\n",
    "        ggplot(data, aes(x='sampling', y=y))\n",
    "        + geom_line()\n",
    "        + geom_point()\n",
    "        # + geom_vline(xintercept=1, linetype='dashed', color='black')\n",
    "        + labs(title=label, x='Sampling', y=None)\n",
    "        + scale_x_continuous(\n",
    "            breaks=data['sampling'],\n",
    "            labels=data['sampling']\n",
    "        )\n",
    "        # + theme_bw()\n",
    "        + theme(\n",
    "            figure_size=(6, 5),\n",
    "            text=element_text(size=14),\n",
    "            plot_title=element_text(\n",
    "                ha=\"left\",\n",
    "                # x=0.535,\n",
    "                margin={'b': 90 if y == 'ssps_speaker_acc' else 90}\n",
    "            ),\n",
    "            # axis_text_x=element_text(angle=45, ha=\"right\")\n",
    "        )\n",
    "    )\n",
    "    p = pw.load_ggplot(p)\n",
    "    return p\n",
    "\n",
    "\n",
    "g_spkacc = create_plot('ssps_speaker_acc', 'Pseudo-Positives Speaker Accuracy (%)')\n",
    "g_vidacc = create_plot('ssps_video_acc', 'Pseudo-Positives Video Accuracy (%)')\n",
    "g_eer = create_plot('test/sv_cosine/voxceleb1_test_O/eer', 'EER (%)')\n",
    "g_mindcf = create_plot('test/sv_cosine/voxceleb1_test_O/mindcf', 'minDCF (p=0.01)')\n",
    "\n",
    "p = (g_eer|g_spkacc|g_vidacc)\n",
    "\n",
    "p.set_suptitle(\n",
    "    \"SSPS-NN: Metrics with different sampling hyper-parameters\",\n",
    "    fontsize=20,\n",
    "    pad=40\n",
    ")\n",
    "p.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSPS-Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from glob import glob\n",
    "import re\n",
    "\n",
    "from plotnine import ggplot, aes, geom_line, geom_vline, geom_point, theme, theme_bw, labs, scale_x_continuous, scale_color_discrete, element_text\n",
    "import patchworklib as pw\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "exps = [\n",
    "    \"models/ssps/voxceleb2/simclr/ssps_kmeans_6k\",\n",
    "    \"models/ssps/voxceleb2/simclr/ssps_kmeans_6k_uni-1\",\n",
    "\n",
    "    \"models/ssps/voxceleb2/simclr/ssps_kmeans_10k\",\n",
    "    \"models/ssps/voxceleb2/simclr/ssps_kmeans_10k_uni-1\",\n",
    "\n",
    "    \"models/ssps/voxceleb2/simclr/ssps_kmeans_25k\",\n",
    "    \"models/ssps/voxceleb2/simclr/ssps_kmeans_25k_uni-1\",\n",
    "    \"models/ssps/voxceleb2/simclr/ssps_kmeans_25k_uni-3\",\n",
    "    \"models/ssps/voxceleb2/simclr/ssps_kmeans_25k_uni-5\",\n",
    "\n",
    "    # \"models/ssps/voxceleb2/simclr/ssps_kmeans-centroid_25k\",\n",
    "    # \"models/ssps/voxceleb2/simclr/ssps_kmeans-centroid_25k_uni-1\",\n",
    "\n",
    "    \"models/ssps/voxceleb2/simclr/ssps_kmeans_50k\",\n",
    "    \"models/ssps/voxceleb2/simclr/ssps_kmeans_50k_uni-1\",\n",
    "    \"models/ssps/voxceleb2/simclr/ssps_kmeans_50k_uni-3\",\n",
    "    \"models/ssps/voxceleb2/simclr/ssps_kmeans_50k_uni-5\",\n",
    "    \"models/ssps/voxceleb2/simclr/ssps_kmeans_50k_uni-10\",\n",
    "\n",
    "    \"models/ssps/voxceleb2/simclr/ssps_kmeans_75k\",\n",
    "    \"models/ssps/voxceleb2/simclr/ssps_kmeans_75k_uni-1\",\n",
    "\n",
    "    \"models/ssps/voxceleb2/simclr/ssps_kmeans_150k\",\n",
    "    \"models/ssps/voxceleb2/simclr/ssps_kmeans_150k_uni-1\",\n",
    "]\n",
    "\n",
    "res = []\n",
    "for exp in exps:\n",
    "    with open(exp + \"/training.json\", \"r\") as f:\n",
    "        train = json.load(f)\n",
    "\n",
    "    with open(exp + \"/evaluation.json\", \"r\") as f:\n",
    "        eval = json.load(f)\n",
    "\n",
    "    inter_sampling = re.search(r'uni-([\\w\\d.]+)', exp.split('/')[-1])\n",
    "    if inter_sampling:\n",
    "        inter_sampling = int(inter_sampling.group(1))\n",
    "    else:\n",
    "        inter_sampling = 0\n",
    "\n",
    "    K = re.search(r'(\\d+)k', exp.split('/')[-1]).group(1) + \"k\"\n",
    "    \n",
    "    res.append({\n",
    "        'inter_sampling': inter_sampling,\n",
    "        'K': K,\n",
    "        **train[\"109\"],\n",
    "        **eval\n",
    "    })\n",
    "\n",
    "data = pd.DataFrame(res)\n",
    "\n",
    "def create_plot(y, label):\n",
    "    p = (\n",
    "        ggplot(data, aes(x='inter_sampling', y=y, color='factor(K)'))\n",
    "        + geom_line()\n",
    "        + geom_point()\n",
    "        # + geom_vline(xintercept=1, linetype='dashed', color='black')\n",
    "        + labs(title=label, x='Inter-cluster sampling', y=None, color='K')\n",
    "        + scale_x_continuous(\n",
    "            breaks=data['inter_sampling'],\n",
    "            labels=data['inter_sampling']\n",
    "        )\n",
    "        + scale_color_discrete(limits=data['K'].unique())\n",
    "        # + theme_bw()\n",
    "        + theme(\n",
    "            figure_size=(6, 5),\n",
    "            text=element_text(size=14),\n",
    "            plot_title=element_text(\n",
    "                ha=\"left\",\n",
    "                # x=0.535,\n",
    "                margin={'b': 90 if y == 'ssps_speaker_acc' else 90}\n",
    "            ),\n",
    "            # axis_text_x=element_text(angle=45, ha=\"right\")\n",
    "        )\n",
    "    )\n",
    "    p = pw.load_ggplot(p)\n",
    "    return p\n",
    "\n",
    "\n",
    "g_spkacc = create_plot('ssps_speaker_acc', 'Pseudo-Positives Speaker Accuracy (%)')\n",
    "g_vidacc = create_plot('ssps_video_acc', 'Pseudo-Positives Video Accuracy (%)')\n",
    "g_eer = create_plot('test/sv_cosine/voxceleb1_test_O/eer', 'EER (%)')\n",
    "g_mindcf = create_plot('test/sv_cosine/voxceleb1_test_O/mindcf', 'minDCF (p=0.01)')\n",
    "\n",
    "p = (g_eer|g_spkacc|g_vidacc)\n",
    "\n",
    "p.set_suptitle(\n",
    "    \"SSPS-Clustering: Metrics with different sampling hyper-parameters\",\n",
    "    fontsize=20,\n",
    "    pad=40\n",
    ")\n",
    "p.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import subprocess\n",
    "\n",
    "\n",
    "res = []\n",
    "for K in [6, 10, 25, 50, 75, 150]:\n",
    "    # Update config\n",
    "    with open('models/ssps/voxceleb2/simclr/DEBUG/config.yml') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    data['method']['ssps']['kmeans_nb_prototypes'] = K * 1000\n",
    "    with open('models/ssps/voxceleb2/simclr/DEBUG/config.yml', 'w') as f:\n",
    "        yaml.dump(data, f)\n",
    "    \n",
    "    # Start training -> capture output\n",
    "    train = subprocess.run(\n",
    "        [\n",
    "            \"./train_ddp.sh\",\n",
    "            \"2\",\n",
    "            'models/ssps/voxceleb2/simclr/DEBUG/config.yml',\n",
    "        ],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "    )\n",
    "\n",
    "    out = json.loads(train.stdout.strip().split(\"\\n\")[-1])\n",
    "\n",
    "    res.append({\n",
    "        'K': K,\n",
    "        'NMI': out[\"nmi_video\"],\n",
    "        'Labels': 'Video'\n",
    "    })\n",
    "\n",
    "    res.append({\n",
    "        'K': K,\n",
    "        'NMI': out[\"nmi_speaker\"],\n",
    "        'Labels': 'Speaker'\n",
    "    })\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import scale_x_log10\n",
    "\n",
    "\n",
    "data = pd.DataFrame(res)\n",
    "\n",
    "p = (\n",
    "    ggplot(data, aes(x='K', y='NMI', color='Labels'))\n",
    "    + geom_line()\n",
    "    + geom_point()\n",
    "    + labs(title=\"NMI for differents values of K\", x='K', y='NMI')\n",
    "    + scale_x_log10(\n",
    "        breaks=data['K'].unique(),\n",
    "        labels=[f\"{k}k\" for k in data['K'].unique()]\n",
    "    )\n",
    "    + theme_bw()\n",
    "    + theme(\n",
    "        figure_size=(12, 8),\n",
    "        text=element_text(size=14),\n",
    "        axis_text_x=element_text(angle=45, ha=\"right\")\n",
    "    )\n",
    ")\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results on SV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vox1o_scores = evaluate_sv([\n",
    "    \"models/ssps/voxceleb2/simclr/baseline/config.yml\",\n",
    "    \"models/ssps/voxceleb2/simclr/ssps_kmeans_25k_uni-1/config.yml\",\n",
    "    \"models/ssps/voxceleb2/simclr/baseline_sup/config.yml\",\n",
    "    \"models/ssps/voxceleb2/simclr/baseline_sup_aam/config.yml\",\n",
    "], 'embeddings_vox1.pt', trials=[\n",
    "    \"voxceleb1_test_O\",\n",
    "])\n",
    "\n",
    "vox1_scores = evaluate_sv([\n",
    "    \"models/ssps/voxceleb2/simclr/baseline/config.yml\",\n",
    "    \"models/ssps/voxceleb2/simclr/ssps_kmeans_25k_uni-1/config.yml\",\n",
    "    \"models/ssps/voxceleb2/simclr/baseline_sup/config.yml\",\n",
    "    \"models/ssps/voxceleb2/simclr/baseline_sup_aam/config.yml\",\n",
    "], 'embeddings_vox1.pt', trials=[\n",
    "    \"voxceleb1_test_O\",\n",
    "    \"voxceleb1_test_E\",\n",
    "    \"voxceleb1_test_H\",\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_distribution(get_models_for_visualization(vox1o_scores, [\n",
    "    \"baseline\",\n",
    "    \"ssps_kmeans_25k_uni-1\",\n",
    "]), use_angle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_distribution(get_models_for_visualization(vox1o_scores, [\n",
    "    \"baseline_sup\",\n",
    "    \"baseline_sup_aam\",\n",
    "]), use_angle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_curve(get_models_for_visualization(vox1o_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from plotnine import ggplot, aes, geom_line, geom_point, theme, labs, scale_x_continuous, element_text\n",
    "import patchworklib as pw\n",
    "\n",
    "\n",
    "with open('models/ssps/voxceleb2/simclr/ssps_kmeans_25k_uni-1/training.json', \"r\") as f:\n",
    "    train = json.load(f)\n",
    "\n",
    "res = []\n",
    "for epoch, metrics in train.items():\n",
    "    res.append({\n",
    "        'Epoch': int(epoch),\n",
    "        'Model': 'SSPS',\n",
    "        **metrics\n",
    "    })\n",
    "\n",
    "with open('models/ssps/voxceleb2/simclr/baseline/training.json', \"r\") as f:\n",
    "    train = json.load(f)\n",
    "\n",
    "for epoch, metrics in train.items():\n",
    "    if epoch == '110':\n",
    "        break\n",
    "    res.append({\n",
    "        'Epoch': int(epoch),\n",
    "        'Model': 'Baseline',\n",
    "        **metrics\n",
    "    })\n",
    "\n",
    "data = pd.DataFrame(res)\n",
    "\n",
    "def create_plot(y, label):\n",
    "    p = (\n",
    "        ggplot(data, aes(x='Epoch', y=y, color='factor(Model)'))\n",
    "        + geom_line()\n",
    "        + geom_point()\n",
    "        + labs(title=label, x='Epoch', y=None, color='Model')\n",
    "        + scale_x_continuous(\n",
    "            breaks=data['Epoch'],\n",
    "            labels=data['Epoch']\n",
    "        )\n",
    "        # + theme_bw()\n",
    "        + theme(\n",
    "            figure_size=(6, 5),\n",
    "            text=element_text(size=14),\n",
    "            plot_title=element_text(\n",
    "                ha='left',\n",
    "                margin={'b': 90}\n",
    "            ),\n",
    "            # axis_text_x=element_text(angle=45, ha=\"right\")\n",
    "        )\n",
    "    )\n",
    "    p = pw.load_ggplot(p)\n",
    "    return p\n",
    "\n",
    "\n",
    "g_loss = create_plot('train/loss', 'Train loss')\n",
    "g_eer = create_plot('val/sv_cosine/voxceleb1_test_O/eer', 'EER (%)')\n",
    "g_mindcf = create_plot('val/sv_cosine/voxceleb1_test_O/mindcf', 'minDCF (p=0.01)')\n",
    "\n",
    "g_spkacc = create_plot('ssps_speaker_acc', 'Pseudo-Positives Speaker Accuracy (%)')\n",
    "g_vidacc = create_plot('ssps_video_acc', 'Pseudo-Positives Video Accuracy (%)')\n",
    "g_nmi = create_plot('ssps_kmeans_nmi', 'NMI on video labels')\n",
    "\n",
    "p = (g_loss|g_eer|g_mindcf)/(g_spkacc|g_vidacc|g_nmi)\n",
    "\n",
    "p.set_suptitle(\n",
    "    \"Convergence of SSPS\",\n",
    "    fontsize=20,\n",
    "    pad=40\n",
    ")\n",
    "p.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intra-speaker similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_intra_class_similarity('speaker', {\n",
    "    'SSL': 'models/ssps/voxceleb2/simclr/baseline/embeddings_vox1.pt',\n",
    "    'SSPS': 'models/ssps/voxceleb2/simclr/ssps_kmeans_25k_uni-1/embeddings_vox1.pt',\n",
    "    'SSL (supervised)': 'models/ssps/voxceleb2/simclr/baseline_sup/embeddings_vox1.pt',\n",
    "    'AAM-Softmax': 'models/ssps/voxceleb2/simclr/baseline_sup_aam/embeddings_vox1.pt',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_intra_class_similarity('speaker', {\n",
    "    'SSL': 'models/ssps/voxceleb2/simclr/baseline/embeddings_vox2.pt',\n",
    "    'SSPS': 'models/ssps/voxceleb2/simclr/ssps_kmeans_25k_uni-1/embeddings_vox2.pt',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inter-speaker similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inter_class_similarity('speaker', {\n",
    "    'SSL': 'models/ssps/voxceleb2/simclr/baseline/embeddings_vox1.pt',\n",
    "    'SSPS': 'models/ssps/voxceleb2/simclr/ssps_kmeans_25k_uni-1/embeddings_vox1.pt',\n",
    "    'SSL (supervised)': 'models/ssps/voxceleb2/simclr/baseline_sup/embeddings_vox1.pt',\n",
    "    'AAM-Softmax': 'models/ssps/voxceleb2/simclr/baseline_sup_aam/embeddings_vox1.pt',\n",
    "}, nb_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inter_speaker_center_similarity({\n",
    "    'SSL': 'models/ssps/voxceleb2/simclr/baseline/embeddings_vox1.pt',\n",
    "    'SSPS': 'models/ssps/voxceleb2/simclr/ssps_kmeans_25k_uni-1/embeddings_vox1.pt',\n",
    "    'SSL (supervised)': 'models/ssps/voxceleb2/simclr/baseline_sup/embeddings_vox1.pt',\n",
    "    'AAM-Softmax': 'models/ssps/voxceleb2/simclr/baseline_sup_aam/embeddings_vox1.pt',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inter_speaker_center_similarity({\n",
    "    'SSL': 'models/ssps/voxceleb2/simclr/baseline/embeddings_vox2.pt',\n",
    "    'SSPS': 'models/ssps/voxceleb2/simclr/ssps_kmeans_25k_uni-1/embeddings_vox2.pt',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intra-video similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_intra_class_similarity('video', {\n",
    "    'SSL': 'models/ssps/voxceleb2/simclr/baseline/embeddings_vox1.pt',\n",
    "    'SSPS': 'models/ssps/voxceleb2/simclr/ssps_kmeans_25k_uni-1/embeddings_vox1.pt',\n",
    "    'SSL (supervised)': 'models/ssps/voxceleb2/simclr/baseline_sup/embeddings_vox1.pt',\n",
    "    'AAM-Softmax': 'models/ssps/voxceleb2/simclr/baseline_sup_aam/embeddings_vox1.pt',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inter-video similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inter_class_similarity('video', {\n",
    "    'SSL': 'models/ssps/voxceleb2/simclr/baseline/embeddings_vox1.pt',\n",
    "    'SSPS': 'models/ssps/voxceleb2/simclr/ssps_kmeans_25k_uni-1/embeddings_vox1.pt',\n",
    "    'SSL (supervised)': 'models/ssps/voxceleb2/simclr/baseline_sup/embeddings_vox1.pt',\n",
    "    'AAM-Softmax': 'models/ssps/voxceleb2/simclr/baseline_sup_aam/embeddings_vox1.pt',\n",
    "}, nb_samples=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_embeddings_vox1 = torch.load(\"models/ssps/voxceleb2/simclr/baseline/embeddings_vox1.pt\")\n",
    "ssps_embeddings_vox1 = torch.load(\"models/ssps/voxceleb2/simclr/ssps_kmeans_25k_uni-1/embeddings_vox1.pt\")\n",
    "\n",
    "baseline_embeddings_vox2 = torch.load(\"models/ssps/voxceleb2/simclr/baseline/embeddings_vox2.pt\")\n",
    "ssps_embeddings_vox2 = torch.load(\"models/ssps/voxceleb2/simclr/ssps_kmeans_25k_uni-1/embeddings_vox2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import labs, theme, element_text\n",
    "import patchworklib as pw\n",
    "\n",
    "\n",
    "def plot_tsne(baseline_embeddings, ssps_embeddings, speakers):    \n",
    "    p1, tsne_init = tsne_2D(Model(\n",
    "        embeddings=baseline_embeddings\n",
    "    ), speakers=speakers)\n",
    "\n",
    "    p2, _ = tsne_2D(Model(\n",
    "        embeddings=ssps_embeddings\n",
    "    ), speakers=speakers, init=tsne_init)\n",
    "\n",
    "\n",
    "    p1 = pw.load_ggplot(\n",
    "        p1\n",
    "        + labs(title=\"Baseline\")\n",
    "        + theme(plot_title=element_text(\n",
    "            ha='left',\n",
    "            margin={'b': 90}\n",
    "        ))\n",
    "    )\n",
    "    p2 = pw.load_ggplot(\n",
    "        p2\n",
    "        + labs(title=\"SSPS\")\n",
    "        + theme(plot_title=element_text(\n",
    "            ha='left',\n",
    "            margin={'b': 90}\n",
    "        ))\n",
    "    )\n",
    "    p = (p1|p2)\n",
    "\n",
    "    p.set_suptitle(\n",
    "        \"t-SNE of speaker representations\",\n",
    "        fontsize=18,\n",
    "        pad=40\n",
    "    )\n",
    "    p.savefig()\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VoxCeleb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne(\n",
    "    baseline_embeddings_vox1,\n",
    "    ssps_embeddings_vox1,\n",
    "    ['id10200', 'id10564', 'id11129', 'id10983', 'id10270', 'id11086', 'id10356', 'id10218', 'id10757', 'id10140']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne(\n",
    "    baseline_embeddings_vox1,\n",
    "    ssps_embeddings_vox1,\n",
    "    ['id10505', 'id10209', 'id10762', 'id10059', 'id10020', 'id10113', 'id10709', 'id10443', 'id11169', 'id10309']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VoxCeleb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne(\n",
    "    baseline_embeddings_vox2,\n",
    "    ssps_embeddings_vox2,\n",
    "    ['id00568', 'id00736', 'id00417', 'id00992', 'id00270', 'id00018', 'id00234', 'id00521', 'id00777', 'id00584']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find speakers for t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import labs, theme, element_text\n",
    "import patchworklib as pw\n",
    "\n",
    "\n",
    "for i in range(50):\n",
    "    speakers = [key.split(\"/\")[-3] for key in baseline_embeddings_vox2.keys()]\n",
    "    speakers = [s for s in list(set(speakers)) if speakers.count(s) >= 150]\n",
    "    import random\n",
    "    speakers = random.sample(speakers, 10)\n",
    "    print(i, speakers)\n",
    "\n",
    "\n",
    "    p1, tsne_init = tsne_2D(Model(\n",
    "        embeddings=baseline_embeddings_vox2\n",
    "    ), speakers=speakers)\n",
    "\n",
    "    p2, _ = tsne_2D(Model(\n",
    "        embeddings=ssps_embeddings_vox2\n",
    "    ), speakers=speakers, init=tsne_init)\n",
    "\n",
    "\n",
    "    p1 = pw.load_ggplot(\n",
    "        p1\n",
    "        + labs(title=\"Baseline\")\n",
    "        + theme(plot_title=element_text(\n",
    "            ha='left',\n",
    "            margin={'b': 90}\n",
    "        ))\n",
    "    )\n",
    "    p2 = pw.load_ggplot(\n",
    "        p2\n",
    "        + labs(title=\"SSPS\")\n",
    "        + theme(plot_title=element_text(\n",
    "            ha='left',\n",
    "            margin={'b': 90}\n",
    "        ))\n",
    "    )\n",
    "    p = (p1|p2)\n",
    "\n",
    "    p.set_suptitle(\n",
    "        \"t-SNE of speaker representations\",\n",
    "        fontsize=18,\n",
    "        pad=40\n",
    "    )\n",
    "    p.savefig()\n",
    "    p.savefig(f\"output{i}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Vox1 metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def fit_mlp_on_representations(embeddings, y_key_pos, test_size=0.2):\n",
    "    keys = list(embeddings.keys())\n",
    "    \n",
    "    X = [embeddings[key][0].numpy() for key in keys]\n",
    "    if y_key_pos is None:\n",
    "        y = keys\n",
    "    else:\n",
    "        y = [key.split('/')[y_key_pos] for key in keys]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=0\n",
    "    )\n",
    "    \n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    print(f'Train accuracy: {clf.score(X_train, y_train)}')\n",
    "    print(f'Test accuracy: {clf.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_embeddings = torch.load(\"models/ssps/voxceleb2/simclr/baseline/embeddings_vox1o_epoch-109.pt\")\n",
    "ssps_embeddings = torch.load(\"models/ssps/voxceleb2/simclr/ssps_kmeans_25k_uni-1/embeddings_vox1o_epoch-109.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = fit_mlp_on_representations(baseline_embeddings, y_key_pos=-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = fit_mlp_on_representations(ssps_embeddings, y_key_pos=-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = fit_mlp_on_representations(baseline_embeddings, y_key_pos=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = fit_mlp_on_representations(ssps_embeddings, y_key_pos=-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = fit_mlp_on_representations(baseline_embeddings, y_key_pos=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = fit_mlp_on_representations(ssps_embeddings, y_key_pos=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
